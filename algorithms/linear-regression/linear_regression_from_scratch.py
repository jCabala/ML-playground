# -*- coding: utf-8 -*-
"""Linear_Regression_From_Scratch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PW8wTI35ctxILvXRKejCPiT9-YaVb9rM
"""

import pandas as pd
import matplotlib.pyplot as plt

"""# Creating Functions for the Regression"""

def loss_function(m, b, points, x_col, y_col):
  total_error = 0
  for i in range(len(points)):
    x = points[x_col][i]
    y = points[y_col][i]
    total_error += (y - (m * x - b)) ** 2

  return total_error / float(len(points))

def gradient_descent(m_cur, b_cur, points, step, x_col, y_col):
  m_gradient = 0
  b_gradient = 0

  n = len(points)

  for i in range(n):
    x = points[x_col][i]
    y = points[y_col][i]

    # Adding partial derivatives
    m_gradient += -(2/n) * x * (y - (m_cur * x + b_cur))
    b_gradient += -(2/n) * (y - (m_cur * x + b_cur))


  m = m_cur - m_gradient * step
  b = b_cur - b_gradient * step

  return m, b

EPOCHS = 1000
STEP = 0.0001
EPOCHS= 1000
def linear_regression(data, x_col, y_col):
  m, b = 0, 0
  for i in range(EPOCHS):
    m, b = gradient_descent(m, b, data, STEP, x_col, y_col)

  return m,b

"""# Performing Regression on a example dataset

"""

df = pd.read_csv('data.csv')
df.head()

m, b = linear_regression(df, x_col='x', y_col='y')
print("The line is mx + b where (m,b) = ", m, b)

plt.scatter(df.x, df.y, color="black")
plt.plot(list(range(0, 100)), [m * x + b for x in range(0, 100)], color="red")